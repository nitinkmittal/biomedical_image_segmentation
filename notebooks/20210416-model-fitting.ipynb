{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c900d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d335b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda, functional, CenterCrop\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import List, Tuple, Any\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from pickle import dump\n",
    "from time import time\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8900a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biomedical_image_segmentation.utils import load_pickle\n",
    "from biomedical_image_segmentation.losses.loss import MSELoss, BCELoss\n",
    "from biomedical_image_segmentation.models.custom_unet import CustomUNet\n",
    "from biomedical_image_segmentation.data.validator import validate \n",
    "from biomedical_image_segmentation.utils import create_dir, empty_dir\n",
    "from biomedical_image_segmentation.plot_utils import plot_results \n",
    "from biomedical_image_segmentation.errors import pixel_error, rand_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206a9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.getcwd().replace(\"notebooks\",\"\")\n",
    "LOGS_PATH = os.path.join(PROJECT_PATH, \"logs\")\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
    "SAMPLES_PATH = os.path.join(DATA_PATH, \"samples\")\n",
    "TRAIN_SAMPLES_PATH = os.path.join(SAMPLES_PATH, \"train\")\n",
    "MASKS_PATH = os.path.join(DATA_PATH, \"masks\")\n",
    "TRAIN_MASKS_PATH = os.path.join(MASKS_PATH, \"train\")\n",
    "\n",
    "AUGMENTED_DATA_PATH = os.path.join(DATA_PATH, \"augmented\")\n",
    "VALID_DATA_PATH = os.path.join(DATA_PATH, \"valid\")\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH, \"test\")\n",
    "\n",
    "# to save all models\n",
    "MODELS_PATH = os.path.join(DATA_PATH, \"model-weights\")\n",
    "\n",
    "MODEL_NAME = \"unet-700-manual-weighted-pixels1\"\n",
    "MODEL_PATH = os.path.join(MODELS_PATH, MODEL_NAME)\n",
    "\n",
    "OPTIMIZER_NAME = f\"{MODEL_NAME}-optimizer\"\n",
    "LR_SCHEDULER_NAME = f\"{MODEL_NAME}-lr-scheduler\"\n",
    "METRICS_NAME = f\"{MODEL_NAME}-metrics\"\n",
    "\n",
    "SCRIPT_NAME = f\"{MODEL_NAME}-model-fitting\"\n",
    "\n",
    "LOG_PATH = os.path.join(LOGS_PATH, MODEL_NAME)\n",
    "LOG_FILE_NAME = os.path.join(LOG_PATH, f\"{SCRIPT_NAME}-{int(time())}.log\")\n",
    "\n",
    "VALIDATE_DATA = True\n",
    "COMPUTE_PIXEL_WEIGHTS = False\n",
    "\n",
    "TRAIN_BATCH_SIZE = 3\n",
    "VALID_BATCH_SIZE = 1\n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "EPOCHS = 8\n",
    "LEARNING_RATE = 3e-4\n",
    "BETAS = (.99, .999)\n",
    "\n",
    "# learning rate scheduler\n",
    "STEP_SIZE = 500\n",
    "GAMMA = .999\n",
    "\n",
    "MIN_LOG_BATCH_WINDOW = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57c4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(LOGS_PATH, True)\n",
    "create_dir(LOG_PATH, True)\n",
    "\n",
    "if os.path.basename(LOG_FILE_NAME) in os.listdir(LOG_PATH): os.remove(LOG_FILE_NAME)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE_NAME,\n",
    "    format='%(asctime)s %(message)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    encoding='utf-8', \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81e73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Number of epochs: {EPOCHS}\")\n",
    "logging.info(f\"Initial learning rate: {LEARNING_RATE: .10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e41b68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Creating directory: {MODELS_PATH}\")\n",
    "create_dir(MODELS_PATH, True)\n",
    "\n",
    "logging.info(f\"Creating directory: {MODEL_PATH}\")\n",
    "create_dir(MODEL_PATH, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee84b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "logging.info(\"Loading train dataset\")\n",
    "train_dataset = []\n",
    "for f in tqdm(os.listdir(path=AUGMENTED_DATA_PATH), leave=False):\n",
    "    train_dataset += load_pickle(os.path.join(AUGMENTED_DATA_PATH, f))\n",
    "    \n",
    "logging.info(\"Loading valid dataset\")\n",
    "valid_dataset = load_pickle(os.path.join(VALID_DATA_PATH, \"valid.pickle\"))\n",
    "\n",
    "logging.info(\"Loading test dataset\")\n",
    "test_dataset = load_pickle(os.path.join(TEST_DATA_PATH, \"test.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2249a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VALIDATE_DATA:\n",
    "    logging.info(\"Validating train dataset\")\n",
    "    validate(train_dataset)\n",
    "\n",
    "    logging.info(\"Validating valid dataset\")\n",
    "    validate(valid_dataset)\n",
    "\n",
    "    logging.info(\"Validating test dataset\")\n",
    "    validate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914f44a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train dataset: 3360\n",
      "Number of samples in valid dataset: 5\n",
      "Number of samples in test dataset: 5\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Number of samples in train dataset: {len(train_dataset)}\")\n",
    "logging.info(f\"Number of samples in valid dataset: {len(valid_dataset)}\")\n",
    "logging.info(f\"Number of samples in test dataset: {len(test_dataset)}\")\n",
    "\n",
    "print(f\"Number of samples in train dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in valid dataset: {len(valid_dataset)}\")\n",
    "print(f\"Number of samples in test dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95cc0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_BATCH_WINDOW = min(len(train_dataset) // 3 + 1, MIN_LOG_BATCH_WINDOW)\n",
    "NUM_TRAIN_BATCHES = len(train_dataset) // TRAIN_BATCH_SIZE + ceil(len(train_dataset) % TRAIN_BATCH_SIZE)\n",
    "NUM_VALID_BATCHES = len(valid_dataset) // VALID_BATCH_SIZE + ceil(len(valid_dataset) % VALID_BATCH_SIZE)\n",
    "NUM_TEST_BATCHES = len(test_dataset) // TEST_BATCH_SIZE + ceil(len(test_dataset) % TEST_BATCH_SIZE)\n",
    "logging.info(\"Preparing train, valid and test data loaders\")\n",
    "logging.info(f\"Batch size: train: {TRAIN_BATCH_SIZE}, valid: {VALID_BATCH_SIZE}, test: {TEST_BATCH_SIZE}\")\n",
    "logging.info(f\"Number of batches train: {NUM_TRAIN_BATCHES}, valid: {NUM_VALID_BATCHES}, test: {NUM_TEST_BATCHES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33b92ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "      self, \n",
    "      dataset: List[Tuple[np.ndarray, np.ndarray]],\n",
    "      image_transformations=None, \n",
    "      mask_transformations=None ):\n",
    "        self.data = dataset\n",
    "        self.image_transformations = image_transformations\n",
    "        self.mask_transformations = mask_transformations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.data[idx]\n",
    "        if self.image_transformations is not None:\n",
    "            img = self.image_transformations(img)\n",
    "            \n",
    "        if self.mask_transformations is not None:\n",
    "            mask = self.mask_transformations(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf503e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformations = Compose(\n",
    "    [\n",
    "#         ToTensor(),\n",
    "        Lambda(lambda x: torch.tensor(np.expand_dims(x, axis=0), dtype=torch.float32)),\n",
    "        Lambda(lambda x: functional.pad(x, padding=94, padding_mode=\"reflect\")),\n",
    "        Normalize(mean=(0.,), std=(255.,)),\n",
    "    ])\n",
    "\n",
    "mask_transformations = Compose(\n",
    "    [\n",
    "#         ToTensor(),\n",
    "        Lambda(lambda x: torch.tensor(np.expand_dims(x, axis=0), dtype=torch.float32)),\n",
    "#         Lambda(lambda x: x.float()),\n",
    "        Normalize(mean=(0.,), std=(255.,))\n",
    "   ])\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=CustomDataset(\n",
    "        train_dataset, \n",
    "        image_transformations=image_transformations, \n",
    "        mask_transformations=mask_transformations), \n",
    "    batch_size = TRAIN_BATCH_SIZE, \n",
    "    shuffle = True)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=CustomDataset(\n",
    "        valid_dataset, \n",
    "        image_transformations=image_transformations, \n",
    "        mask_transformations=mask_transformations), \n",
    "    batch_size = VALID_BATCH_SIZE, \n",
    "    shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=CustomDataset(\n",
    "        test_dataset, \n",
    "        image_transformations=image_transformations, \n",
    "        mask_transformations=mask_transformations), \n",
    "    batch_size = TEST_BATCH_SIZE, \n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d20aef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "if VALIDATE_DATA:\n",
    "    logging.info(\"Validating masks of train, valid and test dataset\")\n",
    "    for X, Y in tqdm(train_loader, leave=False):\n",
    "        assert np.allclose(np.unique(Y), np.array([0., 1.]))\n",
    "\n",
    "    for X, Y in tqdm(valid_loader, leave=False):\n",
    "        assert np.allclose(np.unique(Y), np.array([0., 1.]))\n",
    "\n",
    "    for X, Y in tqdm(test_loader, leave=False):\n",
    "        assert np.allclose(np.unique(Y), np.array([0., 1.]))\n",
    "    logging.info(\"Validation of masks passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb039c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_PIXEL_WEIGHTS:\n",
    "    logging.info(\"Computing weights of 0 and 1 pixel values from train dataset\")\n",
    "    weights = []\n",
    "    for X, Y in tqdm(train_loader, leave=False):\n",
    "        weights.append(np.unique(Y, return_counts=True)[1])\n",
    "\n",
    "    weights = np.mean(np.array(weights), axis=0)\n",
    "    weights /= weights.sum()\n",
    "    weights = 1 - weights\n",
    "else:\n",
    "    weights = (.5, .5)\n",
    "    \n",
    "weights = (.55, .45)\n",
    "logging.info(f\"Weights for pixel values 0. and 1.: {weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab990dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Loading model in CPU\")\n",
    "unet = CustomUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3823f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving at epoch level\n",
    "metrics = {\n",
    "    \"train\": {\"loss\": [], \"pixel-error\": []},\n",
    "    \"valid\": {\"loss\": [], \"pixel-error\": []},\n",
    "    \"min_valid_loss\": 1e10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "836fe3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Checking if model already exists\")\n",
    "\n",
    "if MODEL_NAME in os.listdir(MODEL_PATH):\n",
    "    logging.info(f\"{MODEL_NAME} already exists, loading weights\")\n",
    "    unet.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME)))\n",
    "    metrics = load_pickle(os.path.join(MODEL_PATH, f\"{METRICS_NAME}.pickle\"))\n",
    "    logging.info(f\"Min valid loss: {metrics['min_valid_loss']}\")\n",
    "else:\n",
    "    logging.info(f\"{MODEL_NAME} does not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8671521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f\"GPU available: {True if device.type == 'cuda' else False}\")\n",
    "\n",
    "unet.to(device)\n",
    "\n",
    "logging.info(\"Initiating optimizer\")\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr = LEARNING_RATE, betas=BETAS)\n",
    "\n",
    "logging.info(\"Initiating lr scheduler\")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "if OPTIMIZER_NAME in os.listdir(MODEL_PATH):\n",
    "    logging.info(f\"{OPTIMIZER_NAME} already exists, loading\")\n",
    "    optimizer.load_state_dict(torch.load(os.path.join(MODEL_PATH,OPTIMIZER_NAME)))\n",
    "else:\n",
    "    logging.info(f\"{OPTIMIZER_NAME} does not exists\")\n",
    "\n",
    "if LR_SCHEDULER_NAME in os.listdir(MODEL_PATH):\n",
    "    logging.info(f\"{LR_SCHEDULER_NAME} already exists, loading\")\n",
    "    lr_scheduler.load_state_dict(torch.load(os.path.join(MODEL_PATH,LR_SCHEDULER_NAME)))\n",
    "else:\n",
    "    logging.info(f\"{LR_SCHEDULER_NAME} does not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef2b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    }
   ],
   "source": [
    "t = tqdm(range(EPOCHS), leave=False)\n",
    "for i in t:\n",
    "    with torch.set_grad_enabled(True):\n",
    "        unet.train() \n",
    "        total_loss = 0.\n",
    "        n = 0\n",
    "        for j, (X, Y) in enumerate(train_loader):  \n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = unet(X)\n",
    "            loss = BCELoss(weights=weights, pred=Y_pred, target=Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            n += len(X)\n",
    "            total_loss += loss.item() * len(X) \n",
    "            \n",
    "            info = f\"E: {i}, M: train, B: {j}/{NUM_TRAIN_BATCHES}, BL: {loss.item(): .8f}, LR: {optimizer.state_dict()['param_groups'][0]['lr']: .8f}\"\n",
    "            if j % LOG_BATCH_WINDOW == 0: logging.info(info)\n",
    "            t.set_description(info)\n",
    "        total_loss /= n\n",
    "    metrics[\"train\"][\"loss\"].append(total_loss) \n",
    "    logging.info(f\"Epoch: {i}, mode: train, loss: {total_loss}\")\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        unet.eval() \n",
    "        total_loss = 0.\n",
    "        n = 0\n",
    "        for j, (X, Y) in enumerate(valid_loader):  \n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            Y_pred = unet(X)\n",
    "            loss = BCELoss(weights=weights, pred=Y_pred, target=Y)\n",
    "            n += len(X)\n",
    "            total_loss += loss.item() * len(X)\n",
    "            info = f\"E: {i}, M: valid, B: {j}/{NUM_VALID_BATCHES}, BL: {loss.item(): .8f}\"\n",
    "            if j % LOG_BATCH_WINDOW == 0: logging.info(info)\n",
    "            t.set_description(info)\n",
    "        \n",
    "        total_loss /= n\n",
    "        \n",
    "        if total_loss < metrics[\"min_valid_loss\"]:\n",
    "            logging.info(f\"{'='*10} Updating and saving best model weights {'='*10}\")\n",
    "            metrics[\"min_valid_loss\"] = total_loss\n",
    "            torch.save(unet.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME))\n",
    "            logging.info(f\"{'='*5} Saving optimizer and lr scheduler {'='*5}\")\n",
    "            torch.save(optimizer.state_dict(), os.path.join(MODEL_PATH, OPTIMIZER_NAME))\n",
    "            torch.save(lr_scheduler.state_dict(), os.path.join(MODEL_PATH, LR_SCHEDULER_NAME))\n",
    "            logging.info(f\"Min valid loss: {metrics['min_valid_loss']}\")\n",
    "        \n",
    "    metrics[\"valid\"][\"loss\"].append(total_loss)        \n",
    "    logging.info(f\"Epoch: {i}, mode: valid, loss: {total_loss}\")\n",
    "    \n",
    "    logging.info(\"Saving epoch metrics\")\n",
    "    with open(os.path.join(MODEL_PATH, f\"{METRICS_NAME}.pickle\"), \"wb\") as f:\n",
    "        dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abecf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Loading best model\")\n",
    "unet.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedical_image_segmentation",
   "language": "python",
   "name": "biomedical_image_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
